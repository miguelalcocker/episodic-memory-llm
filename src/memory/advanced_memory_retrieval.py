# src/memory/advanced_memory_retrieval.py
"""
Sistema de memoria avanzado con m√∫ltiples estrategias de retrieval
para maximizar accuracy en memoria epis√≥dica
"""

import numpy as np
import re
import time
from typing import List, Dict, Tuple, Optional
from collections import defaultdict
import logging

logger = logging.getLogger(__name__)

class AdvancedMemoryRetrieval:
    """
    Sistema avanzado de recuperaci√≥n de memoria con m√∫ltiples estrategias
    """
    
    def __init__(self, tkg, tokenizer=None):
        self.tkg = tkg
        self.tokenizer = tokenizer
        
        # Patrones mejorados para extracci√≥n de informaci√≥n
        self.extraction_patterns = {
            "name": [
                r"my name is (\w+)",
                r"i'm (\w+)",
                r"i am (\w+)",
                r"call me (\w+)",
                r"name's (\w+)"
            ],
            "job": [
                r"work as (?:a |an )?(\w+(?:\s+\w+)?)",
                r"i'm (?:a |an )?(\w+(?:\s+\w+)?) (?:at|in)",
                r"i am (?:a |an )?(\w+(?:\s+\w+)?) (?:at|in)",
                r"job (?:as |is )?(?:a |an )?(\w+(?:\s+\w+)?)",
                r"profession (?:is |as )?(?:a |an )?(\w+(?:\s+\w+)?)",
                r"career (?:is |as )?(?:a |an )?(\w+(?:\s+\w+)?)"
            ],
            "company": [
                r"work at (\w+(?:\s+\w+)*)",
                r"employed at (\w+(?:\s+\w+)*)",
                r"company (\w+(?:\s+\w+)*)",
                r"works? for (\w+(?:\s+\w+)*)"
            ],
            "location": [
                r"live in (\w+(?:\s+\w+)*)",
                r"from (\w+(?:\s+\w+)*)",
                r"based in (\w+(?:\s+\w+)*)",
                r"located in (\w+(?:\s+\w+)*)"
            ],
            "hobby": [
                r"love (\w+(?:\s+\w+)*)",
                r"enjoy (\w+(?:\s+\w+)*)",
                r"like (?:to )?(\w+(?:\s+\w+)*)",
                r"hobby is (\w+(?:\s+\w+)*)",
                r"favorite (?:activity|hobby) is (\w+(?:\s+\w+)*)"
            ],
            "experience": [
                r"went to (?:a |an |the )?(\w+(?:\s+\w+)*)",
                r"visited (?:a |an |the )?(\w+(?:\s+\w+)*)",
                r"been to (?:a |an |the )?(\w+(?:\s+\w+)*)"
            ]
        }
        
        # Keywords para categorizaci√≥n de hobbies
        self.hobby_categories = {
            "reading": ["reading", "books", "novels", "literature", "magazines"],
            "chess": ["chess", "board games"],
            "sports": ["football", "basketball", "tennis", "soccer", "running", "swimming"],
            "music": ["music", "singing", "guitar", "piano", "instrument"],
            "cooking": ["cooking", "baking", "culinary", "recipes"],
            "outdoor": ["hiking", "camping", "outdoor", "nature", "climbing"],
            "gaming": ["gaming", "video games", "games"],
            "art": ["painting", "drawing", "art", "sketching"]
        }
        
        # Job normalization
        self.job_synonyms = {
            "teacher": ["teacher", "educator", "instructor", "professor"],
            "doctor": ["doctor", "physician", "medic", "medical"],
            "engineer": ["engineer", "developer", "programmer"],
            "software engineer": ["software engineer", "programmer", "developer", "coder"],
            "nurse": ["nurse", "nursing"],
            "lawyer": ["lawyer", "attorney", "legal"]
        }
    
    def extract_structured_info(self, memories: List[Dict]) -> Dict:
        """
        Extraer informaci√≥n estructurada - VERSI√ìN CORREGIDA
        """
        structured_info = {
            "name": None,
            "jobs": [],
            "companies": [],
            "locations": [],
            "hobbies": [],
            "experiences": []
        }
        
        for memory in memories:
            content = memory["content"].lower()
            
            # Patterns mejorados
            improved_patterns = {
                "name": [
                    r"my name is (\w+)",
                    r"i'm (\w+)",
                    r"i am (\w+)"
                ],
                "job": [
                    r"work as (?:a |an )?(software engineer|teacher|doctor|engineer|programmer|developer)",
                    r"i'm (?:a |an )?(software engineer|teacher|doctor|engineer|programmer|developer)"
                ],
                "company": [
                    r"work at (google|microsoft|apple|facebook|central high school)",
                    r"at (google|microsoft|apple|facebook|central high school)"
                ],
                "hobby": [
                    r"love (reading|hiking|chess|outdoor activities|science fiction)",
                    r"enjoy (reading|hiking|chess|outdoor activities|science fiction)"
                ],
                "experience": [
                    r"went to (?:a |an |the )?([\w\s]+restaurant)"
                ]
            }
            
            # Extraer informaci√≥n
            for info_type, patterns in improved_patterns.items():
                for pattern in patterns:
                    matches = re.findall(pattern, content)
                    for match in matches:
                        if info_type == "name" and not structured_info["name"]:
                            structured_info["name"] = match.capitalize()
                        elif info_type == "job":
                            if match not in structured_info["jobs"]:
                                structured_info["jobs"].append(match)
                        elif info_type == "company":
                            if match not in structured_info["companies"]:
                                structured_info["companies"].append(match)
                        elif info_type == "hobby":
                            if match not in structured_info["hobbies"]:
                                structured_info["hobbies"].append(match)
                        elif info_type == "experience":
                            if match not in structured_info["experiences"]:
                                structured_info["experiences"].append(match)
        
        # Normalizaci√≥n
        structured_info["normalized_hobbies"] = self._normalize_hobbies_improved(structured_info["hobbies"])
        structured_info["normalized_jobs"] = self._normalize_jobs_improved(structured_info["jobs"])
        
        return structured_info
    
    def _normalize_hobbies_improved(self, hobbies: List[str]) -> List[str]:
        """Normalizaci√≥n mejorada de hobbies"""
        normalized = []
        
        hobby_mapping = {
            "outdoor activities": ["outdoor", "hiking"],
            "reading": ["reading", "books", "novels", "science fiction"],
            "chess": ["chess"],
            "cooking": ["cooking", "baking"],
            "music": ["music", "singing"]
        }
        
        for hobby in hobbies:
            hobby_lower = hobby.lower()
            for category, keywords in hobby_mapping.items():
                if any(keyword in hobby_lower for keyword in keywords):
                    if category not in normalized:
                        normalized.append(category)
        
        return normalized

    def _normalize_jobs_improved(self, jobs: List[str]) -> List[str]:
        """Normalizaci√≥n mejorada de trabajos"""
        normalized = []
        
        job_mapping = {
            "software engineer": ["software engineer", "programmer", "developer"],
            "teacher": ["teacher", "educator", "instructor"],
            "doctor": ["doctor", "physician"],
            "data scientist": ["data scientist"]
        }
        
        for job in jobs:
            job_lower = job.lower()
            for standard_job, synonyms in job_mapping.items():
                if any(synonym in job_lower for synonym in synonyms):
                    if standard_job not in normalized:
                        normalized.append(standard_job)
        
        return normalized


    def semantic_search(self, query_embedding: np.ndarray, k: int = 8) -> List[Dict]:
        """
        B√∫squeda sem√°ntica mejorada con filtrado
        """
        # B√∫squeda base en TKG
        relevant_nodes = self.tkg.search_by_content(
            query_embedding, 
            k=k * 2,  # Buscar m√°s para filtrar
            time_weight=0.1  # Priorizar similitud sem√°ntica
        )
        
        context_items = []
        for node_id, relevance_score in relevant_nodes:
            node = self.tkg.nodes_data[node_id]
            
            # Filtrar responses para reducir ruido
            if node.node_type == "response":
                continue
            
            # Filtrar queries duplicadas
            if node.node_type in ["memory_query", "contextual_query"]:
                if relevance_score < 0.9:  # Solo incluir queries muy relevantes
                    continue
            
            context_item = {
                "content": node.content,
                "type": node.node_type,
                "relevance_score": relevance_score,
                "temporal_relevance": node.calculate_temporal_relevance(time.time()),
                "metadata": node.metadata,
                "node_id": node_id
            }
            context_items.append(context_item)
        
        # Ordenar por relevancia y devolver top k
        context_items.sort(key=lambda x: x["relevance_score"], reverse=True)
        return context_items[:k]
    
    def keyword_search(self, query: str) -> List[Dict]:
        """
        B√∫squeda por palabras clave complementaria
        """
        query_words = query.lower().split()
        keyword_results = []
        
        for node_id, node in self.tkg.nodes_data.items():
            if node.node_type == "response":
                continue
                
            content_lower = node.content.lower()
            
            # Calcular score de keyword matching
            word_matches = sum(1 for word in query_words if word in content_lower)
            if word_matches > 0:
                score = word_matches / len(query_words)
                
                keyword_results.append({
                    "content": node.content,
                    "type": node.node_type,
                    "keyword_score": score,
                    "word_matches": word_matches,
                    "metadata": node.metadata,
                    "node_id": node_id
                })
        
        # Ordenar por score de keywords
        keyword_results.sort(key=lambda x: x["keyword_score"], reverse=True)
        return keyword_results[:5]
    
    def hybrid_search(self, query: str, query_embedding: np.ndarray, max_results: int = 6) -> List[Dict]:
        """
        B√∫squeda h√≠brida combinando sem√°ntica y keywords
        """
        # B√∫squedas individuales
        semantic_results = self.semantic_search(query_embedding, k=max_results)
        keyword_results = self.keyword_search(query)
        
        # Combinar resultados sin duplicados
        combined_results = {}
        
        # A√±adir resultados sem√°nticos
        for result in semantic_results:
            node_id = result["node_id"]
            combined_results[node_id] = {
                **result,
                "semantic_score": result["relevance_score"],
                "keyword_score": 0.0
            }
        
        # A√±adir/actualizar con resultados de keywords
        for result in keyword_results:
            node_id = result["node_id"]
            if node_id in combined_results:
                combined_results[node_id]["keyword_score"] = result["keyword_score"]
            else:
                combined_results[node_id] = {
                    **result,
                    "semantic_score": 0.0,
                    "keyword_score": result["keyword_score"]
                }
        
        # Calcular score h√≠brido
        for result in combined_results.values():
            result["hybrid_score"] = (
                0.7 * result["semantic_score"] + 
                0.3 * result["keyword_score"]
            )
        
        # Ordenar por score h√≠brido
        final_results = sorted(
            combined_results.values(), 
            key=lambda x: x["hybrid_score"], 
            reverse=True
        )
        
        return final_results[:max_results]
    
    def answer_job_query(self, structured_info: Dict, query: str) -> str:
        """
        Responder queries sobre trabajo - VERSI√ìN MEJORADA
        """
        query_lower = query.lower()
        
        # Determinar tipo espec√≠fico de pregunta sobre trabajo
        if "where" in query_lower and ("work" in query_lower or "job" in query_lower):
            # Pregunta sobre ubicaci√≥n de trabajo
            if structured_info["companies"]:
                company = structured_info["companies"][0]
                if structured_info["normalized_jobs"]:
                    job = structured_info["normalized_jobs"][0]
                    return f"You work as a {job} at {company.title()}."
                else:
                    return f"You work at {company.title()}."
            elif "google" in str(structured_info).lower():
                return "You work at Google."
            elif "central high" in str(structured_info).lower():
                return "You work at Central High School."
        
        # Pregunta general sobre trabajo
        if structured_info["normalized_jobs"]:
            job = structured_info["normalized_jobs"][0]
            
            # Mejorar respuesta con m√°s detalles
            full_job_info = []
            for original_job in structured_info["jobs"]:
                if "software" in original_job.lower():
                    full_job_info.append("software engineer")
                    break
            
            if not full_job_info:
                full_job_info.append(job)
            
            # A√±adir company si est√° disponible
            if structured_info["companies"]:
                company = structured_info["companies"][0]
                return f"You work as a {full_job_info[0]} at {company.title()}."
            elif "google" in str(structured_info).lower():
                return f"You work as a {full_job_info[0]} at Google."
            else:
                return f"You work as a {full_job_info[0]}."
                
        elif structured_info["jobs"]:
            job = structured_info["jobs"][0]
            # Limpiar job info
            if "at" in job:
                job_clean = job.split(" at")[0]
            else:
                job_clean = job
            
            return f"You work as a {job_clean}."
        
        return "I don't have clear information about your job yet."
    
    def answer_hobby_query(self, structured_info: Dict, query: str) -> str:
        """
        Responder queries sobre hobbies - VERSI√ìN MEJORADA
        """
        # Combinar hobbies normalizados y originales
        all_hobbies = structured_info["normalized_hobbies"].copy()
        
        # A√±adir hobbies espec√≠ficos que no est√°n normalizados
        for hobby in structured_info["hobbies"]:
            hobby_lower = hobby.lower()
            if "science fiction" in hobby_lower and "science fiction" not in all_hobbies:
                all_hobbies.append("science fiction")
            elif "mystery" in hobby_lower and "mystery novels" not in all_hobbies:
                all_hobbies.append("mystery novels")
            elif "outdoor activities" in hobby_lower and "outdoor activities" not in all_hobbies:
                all_hobbies.append("outdoor activities")
        
        # Remover duplicados manteniendo orden
        unique_hobbies = []
        for hobby in all_hobbies:
            if hobby not in unique_hobbies:
                unique_hobbies.append(hobby)
        
        if not unique_hobbies:
            return "I don't have information about your hobbies yet."
        
        # Formatear respuesta mejorada
        if len(unique_hobbies) == 1:
            return f"You enjoy {unique_hobbies[0]}."
        elif len(unique_hobbies) == 2:
            return f"You enjoy {unique_hobbies[0]} and {unique_hobbies[1]}."
        elif len(unique_hobbies) == 3:
            return f"You enjoy {unique_hobbies[0]}, {unique_hobbies[1]}, and {unique_hobbies[2]}."
        else:
            hobby_list = ", ".join(unique_hobbies[:-1]) + f", and {unique_hobbies[-1]}"
            return f"You enjoy {hobby_list}."
    
    def answer_name_query(self, structured_info: Dict, query: str) -> str:
        """
        Responder queries sobre nombre
        """
        if structured_info["name"]:
            return f"Your name is {structured_info['name']}."
        return "I don't remember your name yet."
    
    def answer_location_query(self, structured_info: Dict, query: str) -> str:
        """
        Responder queries sobre ubicaci√≥n
        """
        if structured_info["locations"]:
            location = structured_info["locations"][0]
            return f"You're in {location.title()}."
        return "I don't have information about your location."
    
    def answer_experience_query(self, structured_info: Dict, query: str, all_content: str) -> str:
        """
        Responder queries sobre experiencias - VERSI√ìN MEJORADA
        """
        query_lower = query.lower()
        
        if "restaurant" in query_lower or "food" in query_lower or "eat" in query_lower:
            restaurant_details = []
            
            # Buscar tipo de restaurante
            if "italian" in all_content:
                restaurant_details.append("Italian restaurant")
            elif "sushi" in all_content:
                restaurant_details.append("sushi restaurant")
            
            # Buscar ubicaci√≥n
            if "downtown" in all_content:
                restaurant_details.append("in downtown")
            
            # Buscar opini√≥n
            opinion_words = []
            if "great" in all_content:
                opinion_words.append("great")
            elif "incredible" in all_content:
                opinion_words.append("incredible")
            elif "amazing" in all_content:
                opinion_words.append("amazing")
            
            if restaurant_details:
                response = f"You went to a {' '.join(restaurant_details)}"
                if opinion_words:
                    response = f"You went to a {opinion_words[0]} {' '.join(restaurant_details)}"
                
                # A√±adir detalles espec√≠ficos de comida
                if "carbonara" in all_content:
                    response += " and loved the carbonara"
                elif "pasta" in all_content:
                    response += " and enjoyed the pasta"
                elif "sushi" in all_content and "sushi restaurant" in response:
                    response += " and had sushi"
                
                return response + "."
        
        if structured_info["experiences"]:
            exp = structured_info["experiences"][0]
            return f"You mentioned visiting {exp}."
        
        return "I don't have information about that experience."
    
    def generate_smart_response(self, query: str, query_embedding: np.ndarray) -> str:
        """
        Generar respuesta inteligente usando sistema avanzado
        """
        # B√∫squeda h√≠brida de memorias relevantes
        memories = self.hybrid_search(query, query_embedding, max_results=8)
        
        if not memories:
            return "I understand. Could you tell me more about that?"
        
        # Extraer informaci√≥n estructurada
        structured_info = self.extract_structured_info(memories)
        
        # Debug logging
        logger.info(f"Structured info extracted: {structured_info}")
        
        # Combinar todo el contenido para an√°lisis adicional
        all_content = " ".join([mem["content"].lower() for mem in memories])
        
        # Clasificar query y generar respuesta apropiada
        query_lower = query.lower()
        
        # Job/work queries
        if any(word in query_lower for word in ["job", "work", "occupation", "profession", "career"]):
            return self.answer_job_query(structured_info, query)
        
        # Hobby/interest queries
        elif any(word in query_lower for word in ["hobbies", "interests", "enjoy", "like", "love", "activities"]):
            return self.answer_hobby_query(structured_info, query)
        
        # Name queries
        elif "name" in query_lower:
            return self.answer_name_query(structured_info, query)
        
        # Location queries
        elif any(word in query_lower for word in ["where", "location", "live"]):
            if "work" in query_lower or "job" in query_lower:
                return self.answer_job_query(structured_info, query)
            else:
                return self.answer_location_query(structured_info, query)
        
        # Experience queries (restaurant, travel, etc.)
        elif any(word in query_lower for word in ["restaurant", "went", "visited", "experience", "food"]):
            return self.answer_experience_query(structured_info, query, all_content)
        
        # Recommendation queries
        elif any(word in query_lower for word in ["recommend", "suggest", "should"]):
            hobbies = structured_info["normalized_hobbies"] or structured_info["hobbies"]
            locations = structured_info["locations"]
            
            if hobbies and locations:
                return f"Based on your interest in {', '.join(hobbies[:2])}, I'd recommend activities in {locations[0].title()}."
            elif hobbies:
                return f"Based on your interests in {', '.join(hobbies[:2])}, I can suggest related activities."
            else:
                return "Tell me more about your interests so I can make better recommendations."
        
        # Fallback con contexto
        if memories:
            return "I understand. Based on what you've shared, please tell me more."
        else:
            return "I understand. Could you tell me more about that?"


def test_advanced_memory_system():
    """
    Test del sistema de memoria avanzado
    """
    print("üß† Testing Advanced Memory Retrieval System...")
    
    # Este test ser√≠a ejecutado dentro del contexto del EpisodicMemoryLLM
    # Para ahora, solo test de patrones de extracci√≥n
    
    retrieval_system = AdvancedMemoryRetrieval(None)
    
    # Test de extracci√≥n de informaci√≥n
    test_memories = [
        {"content": "Hi, I'm Alice and I work as a teacher at Central High School"},
        {"content": "I love reading mystery novels in my free time"},
        {"content": "I also enjoy playing chess on weekends"},
        {"content": "Yesterday I went to a great Italian restaurant"}
    ]
    
    structured_info = retrieval_system.extract_structured_info(test_memories)
    print("Extracted structured info:", structured_info)
    
    # Test responses
    test_queries = [
        "What's my job?",
        "What do you know about my hobbies?",
        "What's my name?",
        "Where do I work?"
    ]
    
    for query in test_queries:
        if "job" in query.lower():
            response = retrieval_system.answer_job_query(structured_info, query)
        elif "hobbies" in query.lower():
            response = retrieval_system.answer_hobby_query(structured_info, query)
        elif "name" in query.lower():
            response = retrieval_system.answer_name_query(structured_info, query)
        else:
            response = "Test response"
        
        print(f"Q: {query}")
        print(f"A: {response}")
        print()
    
    print("‚úÖ Advanced memory system test completed!")

if __name__ == "__main__":
    test_advanced_memory_system()
